# Reflection

Student Name:  Connor Cluett
Student Email:  cpcluett@syr.edu

## Instructions

Reflection is a key activity of learning. It helps you build a strong metacognition, or "understanding of your own learning." A good learner not only "knows what they know", but they "know what they don't know", too. Learning to reflect takes practice, but if your goal is to become a self-directed learner where you can teach yourself things, reflection is imperative.

- Now that you've completed the assignment, share your throughts. What did you learn? What confuses you? Where did you struggle? Where might you need more practice?
- A good reflection is: **specific as possible**,  **uses the terminology of the problem domain** (what was learned in class / through readings), and **is actionable** (you can pursue next steps, or be aided in the pursuit). That last part is what will make you a self-directed learner.
- Flex your recall muscles. You might have to review class notes / assigned readings to write your reflection and get the terminology correct.
- Your reflection is for **you**. Yes I make you write them and I read them, but you are merely practicing to become a better self-directed learner. If you read your reflection 1 week later, does what you wrote advance your learning?

Examples:

- **Poor Reflection:**  "I don't understand loops."   
**Better Reflection:** "I don't undersand how the while loop exits."   
**Best Reflection:** "I struggle writing the proper exit conditions on a while loop." It's actionable: You can practice this, google it, ask Chat GPT to explain it, etc. 
-  **Poor Reflection** "I learned loops."   
**Better Reflection** "I learned how to write while loops and their difference from for loops."   
**Best Reflection** "I learned when to use while vs for loops. While loops are for sentiel-controlled values (waiting for a condition to occur), vs for loops are for iterating over collections of fixed values."

`--- Reflection Below This Line ---`
My motivation for doing Sports Betting data is that I am a casual sports bettor who enjoys wagering on games I watch sometimes. I always like to look at the changing odds, as it shows what people across the country are betting and what their opinions on games are, such as who they think is going to win. I was planning to web scrape the popular sites as it looked fairly simple, but then I learned it was actually illegal. So i found a free API, and it turned out the data was really great and It was free. So this is why I stuck with this idea, although I have more ideas to expand on this project and with more time could really polish the app.

Overall this project hopefully showcases my use of Calling APi's, storing in a csv, writing functions to help create a cleaned dataframe, using pandas to clean the dataframes, and then outputting in a streamlit app that updates based on game and shows important metrics and visualizations. I tried to cover most of the stuff we did in class, though I did not get to webscraping, although if I had more time and wanted to in the future I have a lot of ideas using webscraping and combining with my data to output different visualizations and statistics. I struggled a bit with getting the data to load as a json and normalize as one column had all of the data from the sportsbooks, but I figured it out fairly quickly just opening the output in a browser and sort through what I wanted in the data. I also really struggled with making tests, running into error after error, with the main issue being the name of my items, such as the code folder and what I was calling the test_data. I also was struggling with inputting the logos but the streamlit docs helped me realize pngs were the easiest format and to download to my computer instead of using links. I think this project really highlights every topic we covered and shows my skills in making a data pipeline, and the steps needed to ensure a polished app. If I had more time, I would like to incorporate a lot more things. To start, weather data would be cool, also a format that shows all games on a given day such as NFl on a Sunday. Also I would web scrape the ESPN Analytics Predictor because I saw that the moneyline predicted a team would win 66% of the time when ESPN had the team at 75% so this difference in data could be good information for bettors to maximize profits. I also could add a parlay calculator so you do not need to open the sportsbook apps to get the most accurate parlay odds. Finally, If I had more time I would create a simple algorithm that compares the odds in all sportsbooks then highlights the best odds for both teams (For example, if the Patriots had +200 odds to win on 3 sites and +220 on another site to highlight the +220 as it would provide extra money on a win) I would do this for both teams, spreads, and over under to truly maximize your profits. While my app already does this, adding color would make it pop out and make it more user-friendly for sportsbettors who are just starting out. I also could add history data for teams, and I was hoping the API would have that but it didnt. There is so much data that could be helpful but the overall premise of my app is to help bettors get the best odds for the bet they want to make, so any extra data could make the app better if I had more time. Overall, This assignment was fun to work with data that I am interested in and I enjoyed creating an app that could provide potential real world value and implications. 
